Functions
=========
* Implement function composition
- Implement Least Squares
- Implement SVM

Optimizers
==========
- implement steepest descent method
- Implement (L-)BFGS
- Implement primal-dual interior point solver
- implement primal-dual subgradient descent
- test ADMM
- implement projection onto linear constraints

Testing
=======
* Make harness for testing multiple problems on an optimizer

Constraints
===========
- Add better support inequality constraints. There's gotta be something better
  than a log barrier function.
- add support for finding an initial solution

Stopping Criteria
=================
- Implement stopping criterion for Newton's method
- Implement some method to check convergence using duality gap
- Implement some convergence criteria based on size of gradient

Learning Rates
==============
- implement Polyak step size

General
=======
* fix name collisions b/w stopping criteria, learning rates, optimizers
* Add some ways to visually inspect convergence. Logging and plotting a must.
- added symbolic problem definitions
- implement the following interface

  minimize(<expr>)
    .subject_to(<expr>)
    .subject_to(<expr>)
    .using(<algorithm>)

  where <algorithm> is initialized with all algorithm-specific parameters
- implement Lagrangian from problem definition
- deal with multiplication, addition of functions
