Problems
========
- Add Hessian to LogisticRegression
- Implement Least Squares, SVM

Optimizers
==========
- implement steepest descent method
- test proximal method
- Implement Nesterov's accelerated gradient
- Implement (L-)BFGS
- Implement primal-dual interior point solver
- implement primal-dual subgradient descent
- test ADMM
- implement Polyak step size
- implement projection onto linear constraints

Testing
=======
- Make harness for testing multiple problems on an optimizer

Constraints
===========
- Add better support inequality constraints. There's gotta be something better
  than a log barrier function.
- add support for finding an initial solution

General
=======
- change all optimizers to return Solution objects
- added symbolic problem definitions
- Implement some method to check convergence using duality gap
- Implement stopping criterion for Newton's method
- Implement some convergence criteria based on size of gradient
- Add some ways to visually inspect convergence. Logging and plotting a must.
- implement the following interface

  minimize(<expr>)
    .subject_to(<expr>)
    .subject_to(<expr>)
    .using(<algorithm>)

  where <algorithm> is initialized with all algorithm-specific parameters
- implement Lagrangian from problem definition
